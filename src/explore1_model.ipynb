{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This python notebook explores the credit risk classification without using credit score metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97974e26-f18b-422e-b98f-b4696b2de969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os.path as path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pipeline_components import Stage1Classifier, Stage2Classifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a630786-6750-4f57-b050-6fd9f1630ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle.load(open(path.abspath(r'..\\artifacts\\target_associated_data.pkl'), 'rb'))\n",
    "# df = pickle.load(open(r'C:\\Users\\Monika\\Projects\\Credit Risk Checker\\artifacts\\target_associated_data.pkl', 'rb'))\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['Approved_Flag', 'PROSPECTID', 'Credit_Score'], axis=1), \n",
    "                 LabelEncoder().fit_transform(df['Approved_Flag']),\n",
    "                 test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f5f5746-9e56-452d-970a-6723ee682b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1-p3 model score: 0.9600030734138372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.75      1014\n",
      "           1       0.82      0.81      0.81      5045\n",
      "           2       0.34      0.34      0.34      1325\n",
      "           3       0.64      0.67      0.65      1029\n",
      "\n",
      "    accuracy                           0.71      8413\n",
      "   macro avg       0.63      0.64      0.64      8413\n",
      "weighted avg       0.71      0.71      0.71      8413\n",
      "\n",
      "[[ 765  240    7    2]\n",
      " [ 231 4074  627  113]\n",
      " [  42  558  447  278]\n",
      " [   1   89  249  690]]\n"
     ]
    }
   ],
   "source": [
    "xgb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],    \n",
    "    'max_depth': [3, 5, 7],    \n",
    "    'learning_rate': [0.01, 0.1, 0.2],  \n",
    "    'subsample': [0.8, 1.0],   \n",
    "    'colsample_bytree': [0.8, 1.0],     \n",
    "    'gamma': [0, 1],   \n",
    "    'reg_alpha': [0, 1],     \n",
    "    'reg_lambda': [1, 2],    \n",
    "}\n",
    "\n",
    "pipeline = Pipeline(steps=[('stage1', Stage1Classifier(base_model=DecisionTreeClassifier(random_state=42))),\n",
    "                           ('stage2', Stage2Classifier(p1_p3_model=XGBClassifier(random_state=42, n_jobs=-1), \n",
    "                                                       p2_p4_model=DecisionTreeClassifier(random_state=42),\n",
    "                                                       p1_p3_param_grid=xgb_param_grid))\n",
    "                           ])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 1, ..., 2, 1, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 703,  256,   49,    6],\n",
       "       [ 243, 4122,  589,   91],\n",
       "       [  34,  574,  454,  263],\n",
       "       [   0,   91,  254,  684]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, dt.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.69      0.71      1014\n",
      "           1       0.82      0.82      0.82      5045\n",
      "           2       0.34      0.34      0.34      1325\n",
      "           3       0.66      0.66      0.66      1029\n",
      "\n",
      "    accuracy                           0.71      8413\n",
      "   macro avg       0.63      0.63      0.63      8413\n",
      "weighted avg       0.71      0.71      0.71      8413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, dt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Approved_Flag</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P1</th>\n",
       "      <td>701</td>\n",
       "      <td>809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P2</th>\n",
       "      <td>669</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P3</th>\n",
       "      <td>489</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P4</th>\n",
       "      <td>469</td>\n",
       "      <td>658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               min  max\n",
       "Approved_Flag          \n",
       "P1             701  809\n",
       "P2             669  700\n",
       "P3             489  776\n",
       "P4             469  658"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Approved_Flag')['Credit_Score'].agg([\"min\", \"max\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite CIBIL agencies formutes the credit scores using existing customer credit records, the classification model appears to have lost critical predictive power when this metric is excluded. This indicates that the credit score might be capturing nuanced risk factors beyond the raw credit record data.\n",
    "\n",
    "The unexpected degradation of credit risk classification without the credit score suggests that these scores might encapsulate information beyond the credit record data available with us."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
